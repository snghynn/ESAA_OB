{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snghynn/summ/blob/main/week2_%EB%AA%A8%EB%8D%B8%ED%9B%88%EB%A0%A8_%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **| 모델 훈련 연습 문제**\n",
        "___\n",
        "- 출처 : 핸즈온 머신러닝 Ch04 연습문제 1, 5, 9, 10\n",
        "- 개념 문제의 경우 텍스트 셀을 추가하여 정답을 적어주세요."
      ],
      "metadata": {
        "id": "zCu72vDHGMHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. 수백만 개의 특성을 가진 훈련 세트에서는 어떤 선형 회귀 알고리즘을 사용할 수 있을까요?**\n",
        "___\n"
      ],
      "metadata": {
        "id": "j3g-_Dq9GiuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "경사 하강법 method\n",
        "(확률적 경사 하강법, 배치 경사 하강법, 미니배치 경사 하강법 )"
      ],
      "metadata": {
        "id": "aHkSVvCaPb8Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. 배치 경사 하강법을 사용하고 에포크마다 검증 오차를 그래프로 나타내봤습니다. 검증 오차가 일정하게 상승되고 있다면 어떤 일이 일어나고 있는 걸까요? 이 문제를 어떻게 해결할 수 있나요?**\n",
        "___"
      ],
      "metadata": {
        "id": "-pDjW5XcHPOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "검증 오차가 일정하게 상승할 때 훈련 에러도 같이 상승한다면 학습률 에타가 너무 높아서 나타나는 문제이다. 이때 알고리즘이 이리저리 널뛰면서 스텝마다 최적점에서 멀어져 발산하게 된다.\n",
        "\n",
        "따라서 학습률을 낮추면 이 문제를 해결할 수 있다. 덧붙여, 적절한 학습률을 찾기 위해서는 grid search를 이용하면 된다."
      ],
      "metadata": {
        "id": "dFax2Kl5O--K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. 릿지 회귀를 사용했을 때 훈련 오차가 검증 오차가 거의 비슷하고 둘 다 높았습니다. 이 모델에는 높은 편향이 문제인가요, 아니면 높은 분산이 문제인가요? 규제 하이퍼파라미터 $\\alpha$를 증가시켜야 할까요 아니면 줄여야 할까요?**\n",
        "___"
      ],
      "metadata": {
        "id": "nM7JbsLoy7b7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련오차, 검증오차가 비슷하다는 것은 과소적합 -> 높은 편향이 문제. 규제 하이퍼파라미터  α 를 줄여야 한다.\n",
        "\n",
        "cf) 과대적합 (훈련오차 < 검증오차) ->  높은 분산이 문제"
      ],
      "metadata": {
        "id": "XCvjykRRPxx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. 다음과 같이 사용해야 하는 이유는?**\n",
        "___\n",
        "- 평범한 선형 회귀(즉, 아무런 규제가 없는 모델) 대신 릿지 회귀\n",
        "- 릿지 회귀 대신 라쏘 회귀\n",
        "- 라쏘 회귀 대신 엘라스틱넷"
      ],
      "metadata": {
        "id": "C8tARu-ZzOGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 규제가 있어야 성능이 좋음\n",
        "- 라쏘 회귀는  가중치를 완전히 0으로 만드는 경향이 있어 불필요한 변수를 제거할 수 있다.\n",
        "- 라쏘가 어떤 경우에는 불규칙하게 행동하므로, 엘라스틱넷이 대신 쓰인다."
      ],
      "metadata": {
        "id": "vzJir37iRFuL"
      }
    }
  ]
}
